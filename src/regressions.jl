"""
$(TYPEDEF)

---

$(TYPEDFIELDS)
"""
struct LPModel{T <: Real, N}
    # Raw data
    "Raw x data"
    x::AbstractVector{T}
    "Raw y data"
    y::AbstractVector{T}

    # Binned data
    "Binned x data"
    g::Vector{T}
    "Binned y data"
    Y::Vector{T}
    "Bin weights"
    c::Vector{T}

    # Pre-allocated arrays for regressions
    "Kernel weight vector"
    w::Vector{T}
    "x data centered at x‚ÇÄ"
    xÃÇ::AbstractVector{T}
    "Weighting matrix"
    W::Diagonal{T, Vector{T}}
    "Polynomial basis design matrix, centered at x‚ÇÄ"
    X::Matrix{T}
    "`W * X`"
    WX::Matrix{T}
    "`WX' * X`"
    XWX
    "`WX' * Y`"
    XWY::Vector{T}
    "Results vector for `XWX\\XWY`"
    Œ£
    Œ£WX::Matrix{T}
    XWŒ£WX::Matrix{T}
    XWŒ£WXS::Matrix{T}
    VÃÇ::Matrix{T}
end

function show(io::IO, m::LPModel)
    println(io, typeof(m))
    println(io, "        Degree: $(size(m.X, 2)-1)")
    println(io, "  Observations: $(length(m.x))")
    print(  io, "          Bins: $(length(m.g))")
end

function LPModel(x::Vector{T}, y::Vector{T}, degree::Int; nbins::Int=0) where T <: Real
    if nbins > 0
        g, Y, c = linear_binning(x, y; nbins=nbins)
    else
        g, Y, c = x, y, ones(T, size(x))
    end

    # Pre-allocate matrices
    N = degree+1
    w = ones(T, length(g))
    W = Diagonal(w)
    X = _polybasis(g, median(g), degree)
    xÃÇ = view(X, :, 2)
    WX = W*X
    XWX = MMatrix{N, N, T}(WX'X)
    XWY = WX'Y

    Œ£ = UniformScaling(var(g))
    Œ£WX = Œ£*WX
    XWŒ£WX = WX'Œ£WX
    S‚Çô‚Åª¬π = inv(XWX)
    XWŒ£WXS = XWŒ£WX*S‚Çô‚Åª¬π
    VÃÇ = S‚Çô‚Åª¬π*XWŒ£WXS

    return LPModel{T, degree}(x, y, g, Y, c, w, xÃÇ, W, X, WX, XWX, XWY, Œ£, Œ£WX, XWŒ£WX, XWŒ£WXS, VÃÇ)
end

function LPModel(x::Vector{R}, y::Vector{S}; degree::Int=1, nbins::Int=0) where {R<:Real, S<:Real}
    x, y = promote(x, y)
    return LPModel(x, y, degree; nbins)
end

function _polybasis!(X, x, x‚ÇÄ)
    for i in eachindex(x)
        xÃÇ = x[i] - x‚ÇÄ
        xÃÇ·µñ = 1
        for p in 1:size(X, 2)-1
            xÃÇ·µñ *= xÃÇ
            X[i, p+1] = xÃÇ·µñ
        end
    end
    return X
end

function _polybasis(x, x‚ÇÄ, degree)
    X = ones(eltype(x), length(x), degree+1)
    _polybasis!(X, x, x‚ÇÄ)
    return X
end

function _update_weights!(w, xÃÇ, c, h; kernel=Val(:Epanechnikov))
    copyto!(w, c)
    @turbo for i in eachindex(w, xÃÇ)
        w[i] *= K‚Çï(kernel, xÃÇ[i], h)
    end
    return w
end

function _lpreg!(::Val{N}, g, Y, c, w, xÃÇ, W, X, WX, XWX, XWY, x‚ÇÄ, h; kernel=Val(:Epanechnikov)) where {N}
    _polybasis!(X, g, x‚ÇÄ)
    _update_weights!(w, xÃÇ, c, h; kernel)
    mul!(WX, W, X)
    mul!(XWX, WX', X)
    mul!(XWY, WX', Y)
    # ldiv!(Œ≤, lu!(XWX), XWY)
    # return SVector{N+1, eltype(Œ≤)}(Œ≤)
    return lu(XWX)\XWY
end

function _lpreg!(ùêå::LPModel{T, N}, x‚ÇÄ, h; kernel=Val(:Epanechnikov)) where {T, N}
    @unpack g, Y, c, w, xÃÇ, W, X, WX, XWX, XWY = ùêå
    return _lpreg!(Val(N), g, Y, c, w, xÃÇ, W, X, WX, XWX, XWY, x‚ÇÄ, h; kernel)
end

function _lpvcov!(Œ£WX, XWŒ£WX, XWŒ£WXS, VÃÇ, WX, XWX, Œ£)
    S‚Çô‚Åª¬π = inv(XWX)
    mul!(Œ£WX, Œ£, WX)
    mul!(XWŒ£WX, WX', Œ£WX)
    rmul!(XWŒ£WX, 1/size(Œ£WX, 1))
    mul!(XWŒ£WXS, XWŒ£WX, S‚Çô‚Åª¬π)
    mul!(VÃÇ, S‚Çô‚Åª¬π, XWŒ£WXS)
    return VÃÇ
end

function _lpvcov!(ùêå::LPModel)
    @unpack Œ£WX, XWŒ£WX, XWŒ£WXS, VÃÇ, WX, XWX, Œ£ = ùêå
    return _lpvcov!(Œ£WX, XWŒ£WX, XWŒ£WXS, VÃÇ, WX, XWX, Œ£)
end

function _lpvcov(::Val{N}, xÃÇ, WX, XWX) where {N}
    œÉ¬≤ = var(xÃÇ)
    S‚Çô‚Åª¬π = inv(XWX)
    VÃÇ = S‚Çô‚Åª¬π * WX' * œÉ¬≤ * WX * S‚Çô‚Åª¬π / length(xÃÇ)
    return SMatrix{N+1, N+1, eltype(VÃÇ)}(VÃÇ)
end

function _lpvcov(ùêå::LPModel{T, N}) where {T, N}
    @unpack xÃÇ, WX, XWX = ùêå
    return _lpvcov(Val(N), xÃÇ, WX, XWX)
end

"""
Estimate the local polynomial regression model `ùêå` at the points in `v`.

$(TYPEDSIGNATURES)

## Arguments
- `ùêå::LPModel`
- `v::AbstractVector`

## Keyword Arguments
- `kernel=Val(:Epanechnikov)` - kernel function
- `h=plugin_bandwidth(x, y, size(ùêå.X, 2)-1, size(ùêå.X, 2); kernel)` - bandwidth
- `se::Bool=false` - flag for whether standard errors should be computed and returned
"""
function lpreg!(
    ùêå::LPModel{T, N},
    v::AbstractVector;
    kernel=:Epanechnikov,
    h=plugin_bandwidth(ùêå.x, ùêå.y; ŒΩ=max(size(ùêå.X, 2)-2, 0), p=size(ùêå.X, 2)-1, kernel),
    se::Bool=false,
) where {T, N}
    # Get initial values
    Œ≤ÃÇ = _lpreg!(ùêå, first(v), h; kernel=Val(kernel))
    se && (VÃÇ = SMatrix{N+1, N+1, T}(_lpvcov!(ùêå)))

    # Construct vectors for results
    ùõÉ = Vector{typeof(Œ≤ÃÇ)}(undef, length(v)); ùõÉ[1] = Œ≤ÃÇ
    se && (ùêï = Vector{typeof(VÃÇ)}(undef, length(v)); ùêï[1] = VÃÇ)

    # Populate vectors for remaining regressions
    for i in Base.Iterators.drop(eachindex(v), 1)
        @inbounds ùõÉ[i] = _lpreg!(ùêå, v[i], h; kernel=Val(kernel))
        se && (@inbounds ùêï[i] = SMatrix{N+1, N+1, T}(_lpvcov!(ùêå)))
    end

    return se ? (ùõÉ, ùêï) : ùõÉ
end

"""
Estimate the local polynomial regression of `y` on `x` at the points in `v`.

$(TYPEDSIGNATURES)

## Arguments
- `x::AbstractVector`
- `y::AbstractVector`
- `v::AbstractVector`

## Keyword Arguments
- `degree::Int=1` - degree of the polynomial approximation
- `nbins::Int=floor(Int, length(x)/100)` - number of bins to use (0 for no binning)
- `kernel=Val(:Epanechnikov)` - kernel function
- `h=plugin_bandwidth(x, y, size(ùêå.X, 2)-1, size(ùêå.X, 2); kernel)` - bandwidth
- `se::Bool=false` - flag for whether standard errors should be computed and returned
"""
function lpreg(
    x::AbstractVector,
    y::AbstractVector,
    v::AbstractVector;
    degree::Int=1,
    nbins::Int=floor(Int, length(x)/100),
    kernel=:Epanechnikov,
    h=plugin_bandwidth(x, y; ŒΩ=degree-1, p=degree, kernel),
    se=false,
)
    ùêå = LPModel(x, y, degree; nbins)
    return lpreg!(ùêå, v; kernel, h, se)
end
